
Предполагаемая структура сервиса:

- prediction_api.py — приложение Flask, которое взаимодействует с клиентом и возвращает предсказание модели
- model.py — файл с функциями загрузки моделей
- models/ — папка с сохранёнными моделями
- logs/ — папка с логами

Для создания контейнера нужно запустить следующие команды из корневой директории проекта

`docker build . -t <image_name>`
`docker run -p <host_port>:5000 -it --name <container_name> <image_name>`

Где:
- host_port - порт, по которому предполагается обращаться к апи
- image_name - название образа (может быть любым)
- container_name - название контейнера (может быть любым)

Доступ к API должен осуществляться по следующему URL:

`http://[hostname]/iris/api/v1.0/getpred`

В качестве примера запроса можно использовать:

`http://[hostname]/iris/api/v1.0/getpred?sepal_length=5.1&sepal_width=3.5&petal_length=1.4&petal_width=0.2`

После обращения API возвращает job_id, с помощью которого можно получить следующую информацию

- статус выполнения запроса к сервису по адресу:

`http://[hostname]/iris/api/v1.0/status/<job_id>`

- результат работы модели по адресу:

`http://[hostname]/iris/api/v1.0/result/<job_id>`
